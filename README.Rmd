---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(dplyr); library(targets);library(arrow)
tar_visnetwork() %>% 
  visNetwork::visSave("docs/index.html")

```

# climateR-catalogs

<!-- badges: start -->
<!-- badges: end -->

The goal of `climateR-catalogs` is to "automate" a collection of data catalogs usable with `terra`, `climateR`, `gdalio`, `geoknife`, `stars`, etc.

The catalog(s) will be built using `targets` in this repo, and deployed as JSON/parquet/rds artifacts at "https://mikejohnson51.github.io/climateR-catalogs/catalog.{ext}". 

Hopefully a more authoritative home at USGS or NOAA can be found to host these.

## Scope

The catalog will hope to support 4 types of data source and will limit itself to non-authenticated public data assets. The included types will be:

1. Aggregated NetCDF (via OpenDap)
2. Non aggregated NetCDF (via OpenDap)
3. tif/COG/vrt hosted by s3/FTP/ect
4. STAC catalog (WIP)

## Targets

Targets will be used in an attempt to ensure maintenance is possible. The interactive version of the latest run can be seen here [here](https://mikejohnson51.github.io/climateR-catalogs/)

## Schema

To align the 4 categories of data a WIP schema can be found [here](https://mikejohnson51.github.io/climateR-catalogs/schema.html)

### Catalog to date:

The catalog looks like this on `r Sys.Date()` reading local version (same as pushed one found in `docs`)

```{r}
cat =  read_parquet("docs/catalog.parquet")

# Unique datasets
nrow(cat)

# Unique products
length(unique(cat$asset))

```


### Examples

Here is a minimal example with the base information added:

```{r cars}
pacman::p_load(dplyr, opendap.catalog, AOI, terra)

nlcd = filter(cat, id == "NLCD", asset == '2019 Land Cover L48')

t(nlcd)
```

```{r}
(output   = dap(catalog = nlcd,  AOI = aoi_get("Fort Collins")))

plot(output)
```

This is still a little clunky but you can pass multi-row "catalog" data.frames straight to 
dap! For example say you want soil sand content, land cover and elevation for the city of Fort Collins:

```{r}
multilayer = filter(cat,  asset %in% c("2019 Land Cover L48", "30m CONUS DEM", "sand_mean_0_5"))

output  = lapply(1:nrow(multilayer), function(x){   dap(catalog = multilayer[x,], AOI = aoi_get("Fort Collins")) })

par(mfrow = c(2,2))
for(i in 1:3){
  plot(output[[i]], main = multilayer$product[i])  
}  
```

### Hitting OpenDap resources!

```{r}
dap_resource = filter(cat, 
             id == 'bcca', 
             variable  ==	'tasmin',	
             model == 'MPI-ESM-LR', 
             ensemble == 'r1i1p1',
             scenario == "historical") 

t(dap_resource)

data = dap(URL  = dap_resource$URL, 
           AOI = aoi_get(state = "FL"), 
           varname = dap_resource$varname,
           startDate = "2000-10-01",
           endDate   = "2000-10-04")

plot(data[[1]])
```

### Global

```{r}
nz_soil = filter(cat, id == "ISRIC Soil Grids", variable == 'silt_0-5cm_mean')

data = dap(URL  = nz_soil$URL,  AOI = aoi_get(country  = "New Zealand"))

plot(data[[1]])
```
